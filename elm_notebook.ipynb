{
 "metadata": {
  "name": "elm_notebook"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# -*- coding: utf-8 -*-\n",
      "# <nbformat>2</nbformat>"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# <codecell>\n",
      "\n",
      "# Demo python notebook for sklearn elm and random_hidden_layer modules\n",
      "#\n",
      "# Author: David C. Lambert [dcl -at- panix -dot- com]\n",
      "# Copyright(c) 2013\n",
      "# License: Simple BSD"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# <codecell>\n",
      "\n",
      "import numpy as np\n",
      "from numpy import sqrt\n",
      "from pylab import plot, hist, mean, std, scatter, show\n",
      "\n",
      "from time import time\n",
      "from sklearn.cluster import k_means\n",
      "\n",
      "from elm import ELMClassifier, ELMRegressor, GenELMClassifier, GenELMRegressor\n",
      "from random_layer import RandomLayer, MLPRandomLayer, RBFRandomLayer, GRBFRandomLayer"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# <codecell>\n",
      "\n",
      "\n",
      "def make_toy():\n",
      "    x = np.arange(0.25, 20, 0.1)\n",
      "    y = x * np.cos(x) + 0.5 * sqrt(x) * np.random.randn(x.shape[0])\n",
      "    x = x.reshape(-1, 1)\n",
      "    y = y.reshape(-1, 1)\n",
      "    return x, y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# <codecell>\n",
      "\n",
      "\n",
      "def res_dist(x, y, e, n_runs=100, random_state=None):\n",
      "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=random_state)\n",
      "\n",
      "    test_res = []\n",
      "    train_res = []\n",
      "    start_time = time()\n",
      "\n",
      "    for i in xrange(n_runs):\n",
      "        e.fit(x_train, y_train)\n",
      "        train_res.append(e.score(x_train, y_train))\n",
      "        test_res.append(e.score(x_test, y_test))\n",
      "        if (i % (n_runs / 10) == 0):\n",
      "            print \"%d\" % i,\n",
      "\n",
      "    print \"\\nTime: %.3f secs\" % (time() - start_time)\n",
      "\n",
      "    print \"Test Min: %.3f Mean: %.3f Max: %.3f SD: %.3f\" % (min(test_res), mean(test_res), max(test_res), std(test_res))\n",
      "    print \"Train Min: %.3f Mean: %.3f Max: %.3f SD: %.3f\" % (min(train_res), mean(train_res), max(train_res), std(train_res))\n",
      "    print\n",
      "    return (train_res, test_res)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# <codecell>\n",
      "\n",
      "from sklearn.cross_validation import train_test_split\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn.datasets import load_iris, load_digits, load_diabetes, make_regression\n",
      "\n",
      "stdsc = StandardScaler()\n",
      "\n",
      "iris = load_iris()\n",
      "irx, iry = stdsc.fit_transform(iris.data), iris.target\n",
      "irx_train, irx_test, iry_train, iry_test = train_test_split(irx, iry, test_size=0.2)\n",
      "\n",
      "digits = load_digits()\n",
      "dgx, dgy = stdsc.fit_transform(digits.data / 16.0), digits.target\n",
      "dgx_train, dgx_test, dgy_train, dgy_test = train_test_split(dgx, dgy, test_size=0.2)\n",
      "\n",
      "diabetes = load_diabetes()\n",
      "dbx, dby = stdsc.fit_transform(diabetes.data), diabetes.target\n",
      "dbx_train, dbx_test, dby_train, dby_test = train_test_split(dbx, dby, test_size=0.2)\n",
      "\n",
      "mrx, mry = make_regression(n_samples=2000, n_targets=4)\n",
      "mrx_train, mrx_test, mry_train, mry_test = train_test_split(mrx, mry, test_size=0.2)\n",
      "\n",
      "xtoy, ytoy = make_toy()\n",
      "xtoy, ytoy = stdsc.fit_transform(xtoy), stdsc.fit_transform(ytoy)\n",
      "xtoy_train, xtoy_test, ytoy_train, ytoy_test = train_test_split(xtoy, ytoy, test_size=0.2)\n",
      "\n",
      "plot(xtoy, ytoy)\n",
      "show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# <codecell>\n",
      "\n",
      "# RBFRandomLayer tests\n",
      "for af in RandomLayer.activation_func_names():\n",
      "    print af,\n",
      "    elmc = ELMClassifier(activation_func=af)\n",
      "    tr, ts = res_dist(irx, iry, elmc, n_runs=200, random_state=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# <codecell>\n",
      "\n",
      "elmc.classes_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# <codecell>\n",
      "\n",
      "for af in RandomLayer.activation_func_names():\n",
      "    print af\n",
      "    elmc = ELMClassifier(activation_func=af, random_state=0)\n",
      "    tr, ts = res_dist(dgx, dgy, elmc, n_runs=100, random_state=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# <codecell>\n",
      "\n",
      "elmc = ELMClassifier(n_hidden=500, activation_func='multiquadric')\n",
      "tr, ts = res_dist(dgx, dgy, elmc, n_runs=100, random_state=0)\n",
      "scatter(tr, ts, alpha=0.1, marker='D', c='r')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# <codecell>\n",
      "\n",
      "elmr = ELMRegressor(random_state=0, activation_func='gaussian', alpha=0.0)\n",
      "elmr.fit(xtoy_train, ytoy_train)\n",
      "print elmr.score(xtoy_train, ytoy_train), elmr.score(xtoy_test, ytoy_test)\n",
      "plot(xtoy, ytoy)\n",
      "show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# <codecell>\n",
      "\n",
      "from sklearn import pipeline\n",
      "from sklearn.linear_model import LinearRegression, Ridge\n",
      "elmr = pipeline.Pipeline([('rhl', RandomLayer(random_state=0, activation_func='multiquadric')),\n",
      "                          ('lr', Ridge(alpha=0, fit_intercept=True))])\n",
      "elmr.fit(xtoy_train, ytoy_train)\n",
      "print elmr.score(xtoy_train, ytoy_train), elmr.score(xtoy_test, ytoy_test)\n",
      "plot(xtoy, ytoy, xtoy, elmr.predict(xtoy))\n",
      "show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# <codecell>\n",
      "\n",
      "rhl = RandomLayer(n_hidden=200, alpha=1.0)\n",
      "elmr = GenELMRegressor(hidden_layer=rhl)\n",
      "tr, ts = res_dist(mrx, mry, elmr, n_runs=200, random_state=0)\n",
      "scatter(tr, ts, alpha=0.1, marker='D', c='r')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# <codecell>\n",
      "\n",
      "rhl = RBFRandomLayer(n_hidden=15, rbf_width=0.8)\n",
      "elmr = GenELMRegressor(hidden_layer=rhl)\n",
      "elmr.fit(xtoy_train, ytoy_train)\n",
      "print elmr.score(xtoy_train, ytoy_train), elmr.score(xtoy_test, ytoy_test)\n",
      "plot(xtoy, ytoy, xtoy, elmr.predict(xtoy))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# <codecell>\n",
      "\n",
      "nh = 15\n",
      "(ctrs, _, _) = k_means(xtoy_train, nh)\n",
      "unit_rs = np.ones(nh)\n",
      "\n",
      "# rhl = RBFRandomLayer(n_hidden=nh, activation_func='inv_multiquadric')\n",
      "# rhl = RBFRandomLayer(n_hidden=nh, centers=ctrs, radii=unit_rs)\n",
      "rhl = GRBFRandomLayer(n_hidden=nh, grbf_lambda=.0001, centers=ctrs)\n",
      "elmr = GenELMRegressor(hidden_layer=rhl)\n",
      "elmr.fit(xtoy_train, ytoy_train)\n",
      "print elmr.score(xtoy_train, ytoy_train), elmr.score(xtoy_test, ytoy_test)\n",
      "plot(xtoy, ytoy, xtoy, elmr.predict(xtoy))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# <codecell>\n",
      "\n",
      "rbf_rhl = RBFRandomLayer(n_hidden=100, random_state=0, rbf_width=0.01)\n",
      "elmc_rbf = GenELMClassifier(hidden_layer=rbf_rhl)\n",
      "elmc_rbf.fit(dgx_train, dgy_train)\n",
      "print elmc_rbf.score(dgx_train, dgy_train), elmc_rbf.score(dgx_test, dgy_test)\n",
      "\n",
      "\n",
      "def powtanh_xfer(activations, power=1.0):\n",
      "    return pow(np.tanh(activations), power)\n",
      "\n",
      "tanh_rhl = MLPRandomLayer(n_hidden=100, activation_func=powtanh_xfer, activation_args={'power': 3.0})\n",
      "elmc_tanh = GenELMClassifier(hidden_layer=tanh_rhl)\n",
      "elmc_tanh.fit(dgx_train, dgy_train)\n",
      "print elmc_tanh.score(dgx_train, dgy_train), elmc_tanh.score(dgx_test, dgy_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# <codecell>\n",
      "\n",
      "rbf_rhl = RBFRandomLayer(n_hidden=100, rbf_width=0.01)\n",
      "tr, ts = res_dist(dgx, dgy, GenELMClassifier(hidden_layer=rbf_rhl), n_runs=100, random_state=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# <codecell>\n",
      "\n",
      "hist(ts), hist(tr)\n",
      "print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# <codecell>\n",
      "\n",
      "from sklearn.ensemble import RandomForestRegressor\n",
      "tr, ts = res_dist(dbx, dby, RandomForestRegressor(n_estimators=15), n_runs=100, random_state=0)\n",
      "hist(tr), hist(ts)\n",
      "print\n",
      "\n",
      "rhl = RBFRandomLayer(n_hidden=15, rbf_width=0.1)\n",
      "tr, ts = res_dist(dbx, dby, GenELMRegressor(rhl), n_runs=100, random_state=0)\n",
      "hist(tr), hist(ts)\n",
      "print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# <codecell>\n",
      "\n",
      "elmc = ELMClassifier(n_hidden=1000, activation_func='gaussian', alpha=0.0, random_state=0)\n",
      "elmc.fit(dgx_train, dgy_train)\n",
      "print elmc.score(dgx_train, dgy_train), elmc.score(dgx_test, dgy_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# <codecell>\n",
      "\n",
      "elmc = ELMClassifier(n_hidden=500, activation_func='hardlim', alpha=1.0, random_state=0)\n",
      "elmc.fit(dgx_train, dgy_train)\n",
      "print elmc.score(dgx_train, dgy_train), elmc.score(dgx_test, dgy_test)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# <codecell>\n",
      "\n",
      "elmr = ELMRegressor(random_state=0)\n",
      "elmr.fit(xtoy_train, ytoy_train)\n",
      "print elmr.score(xtoy_train, ytoy_train), elmr.score(xtoy_test, ytoy_test)\n",
      "plot(xtoy, ytoy, xtoy, elmr.predict(xtoy))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# <codecell>\n",
      "\n",
      "elmr = ELMRegressor(activation_func='inv_tribas', random_state=0)\n",
      "elmr.fit(xtoy_train, ytoy_train)\n",
      "print elmr.score(xtoy_train, ytoy_train), elmr.score(xtoy_test, ytoy_test)\n",
      "plot(xtoy, ytoy, xtoy, elmr.predict(xtoy))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}